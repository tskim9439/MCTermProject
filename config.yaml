batchSize : 100
epoch : 100
hidden_size : 100
validation : True

model :
  name : "transformer_beta" # [lstm, gru, transformer, lstm_beta, gru_beta, transformer_beta, srgnn]
  
  srgnn :
    hidden_size : 100    #최초 100 -> 256  1209 1715
    batchSize : 100
    step : 3            #최초 3 -> 1 -> 2 -> 5 (1209 1730 -> 1733 -> 1752)
    lr : 0.001
    lr_dc : 0.1
    lr_dc_step : 3      #최초 3 -> 5
    l2 : 0.0001
    nonhybrid : False
  
  lstm :
    lr : 0.001
    lr_dc : 0.1
    lr_dc_step : 3
    l2 : 0.0001
  
  gru :
    lr : 0.001
    lr_dc : 0.1
    lr_dc_step : 3
    l2 : 0.0001

  transformer :
    hidden_size : 100
    num_layers : 3
    dropout : 0.0
    lr : 0.001
    lr_dc : 0.1
    lr_dc_step : 3
    l2 : 0.0001

  lstm_beta:
    lr : 0.001
    lr_dc : 0.1
    lr_dc_step : 3
    l2 : 0.0001
    hidden_size : 100   #최초 100 -> 256  1209 1715
    batchSize : 100
    step : 3            #최초 3 -> 1 -> 2 -> 5 (1209 1730 -> 1733 -> 1752)
    nonhybrid : False

  gru_beta:
    lr : 0.001
    lr_dc : 0.1
    lr_dc_step : 3
    l2 : 0.0001
    hidden_size : 100   #최초 100 -> 256  1209 1715
    batchSize : 100
    step : 3            #최초 3 -> 1 -> 2 -> 5 (1209 1730 -> 1733 -> 1752)
    nonhybrid : False

  transformer_beta:
    lr : 0.001
    lr_dc : 0.1
    lr_dc_step : 3
    l2 : 0.0001
    hidden_size : 100   #최초 100 -> 256  1209 1715
    batchSize : 100
    num_layers : 3    
    step : 3            #최초 3 -> 1 -> 2 -> 5 (1209 1730 -> 1733 -> 1752)
    nonhybrid : False
